{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-f69b4c90ca77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# split data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# tune model hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'split' is not defined"
     ]
    }
   ],
   "source": [
    "# PSEUDOCODE\n",
    "\n",
    "# split data\n",
    "data = ...\n",
    "train, validation, test = split(data)\n",
    " \n",
    "# tune model hyperparameters\n",
    "parameters = ...\n",
    "for params in parameters:\n",
    "\tmodel = fit(train, params)\n",
    "\tskill = evaluate(model, validation)\n",
    " \n",
    "# evaluate final model for comparison with other models\n",
    "model = fit(train)\n",
    "skill = evaluate(model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import os, shutil, keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Convolution2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directories with training, validation, test cat/dog pics\n",
    "\n",
    "train_dir = os.path.abspath(\"/Users/Nadia/Desktop/FinalProject490/train\")\n",
    "validation_dir = os.path.abspath(\"/Users/Nadia/Desktop/FinalProject490/validation\")\n",
    "test_dir = os.path.abspath(\"/Users/Nadia/Desktop/FinalProject490/test\")\n",
    "\n",
    "train_rock = os.path.join(train_dir, \"train_rock\")\n",
    "train_paper = os.path.join(train_dir, \"train_paper\")\n",
    "train_scissors = os.path.join(train_dir, \"train_scissors\")\n",
    "\n",
    "validation_rock = os.path.join(validation_dir, \"validation_rock\")\n",
    "validation_paper = os.path.join(validation_dir, \"validation_paper\")\n",
    "validation_scissors = os.path.join(validation_dir, \"validation_scissors\")\n",
    "\n",
    "test_rock = os.path.join(test_dir, \"test_rock\")\n",
    "test_paper = os.path.join(test_dir, \"test_paper\")\n",
    "test_scissors = os.path.join(test_dir, \"test_scissors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), activation='relu',\n",
    "input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_61 (Conv2D)           (None, 148, 148, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 74, 74, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 72, 72, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_33 (Flatten)         (None, 41472)             0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 128)               5308544   \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 5,314,019\n",
      "Trainable params: 5,314,019\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Save model & summary\n",
    "\n",
    "model.save('rps_model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1531 images belonging to 3 classes.\n",
      "Found 437 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# data-augmentation generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,  #target directory\n",
    "    target_size = (150, 150),\n",
    "    batch_size = 16,\n",
    "    shuffle = True,\n",
    "    class_mode = 'categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,  #target directory\n",
    "    target_size = (150, 150),\n",
    "    batch_size = 16,\n",
    "    shuffle = True,\n",
    "    class_mode = 'categorical')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_paper': 0, 'train_rock': 1, 'train_scissors': 2}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model for training\n",
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "    optimizer =keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.999, amsgrad=False),\n",
    "    metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 97s 966ms/step - loss: 1.1125 - acc: 0.3693 - val_loss: 1.0120 - val_acc: 0.5577\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 74s 742ms/step - loss: 1.0509 - acc: 0.4408 - val_loss: 1.0171 - val_acc: 0.5501\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 46s 459ms/step - loss: 1.0147 - acc: 0.5028 - val_loss: 0.8866 - val_acc: 0.7442\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 33s 326ms/step - loss: 0.9751 - acc: 0.5266 - val_loss: 0.7426 - val_acc: 0.8046\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 34s 340ms/step - loss: 0.9605 - acc: 0.5354 - val_loss: 0.7222 - val_acc: 0.8758\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 35s 350ms/step - loss: 0.9172 - acc: 0.5698 - val_loss: 0.7223 - val_acc: 0.8085\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 69s 687ms/step - loss: 0.8818 - acc: 0.5994 - val_loss: 0.6309 - val_acc: 0.9190\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 74s 744ms/step - loss: 0.8286 - acc: 0.6325 - val_loss: 0.5868 - val_acc: 0.9087\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 67s 669ms/step - loss: 0.8117 - acc: 0.6677 - val_loss: 0.6178 - val_acc: 0.8779\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 68s 684ms/step - loss: 0.7955 - acc: 0.6614 - val_loss: 0.4715 - val_acc: 0.8999\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 55s 553ms/step - loss: 0.7435 - acc: 0.7003 - val_loss: 0.6116 - val_acc: 0.9550\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 0.7319 - acc: 0.7266 - val_loss: 0.4464 - val_acc: 0.8792\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 38s 376ms/step - loss: 0.6594 - acc: 0.7541 - val_loss: 0.5549 - val_acc: 0.8612\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 36s 362ms/step - loss: 0.6707 - acc: 0.7555 - val_loss: 0.4037 - val_acc: 0.9370\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 42s 416ms/step - loss: 0.6432 - acc: 0.7525 - val_loss: 0.2635 - val_acc: 0.9379\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 35s 351ms/step - loss: 0.6037 - acc: 0.7855 - val_loss: 0.1993 - val_acc: 0.9499\n",
      "Epoch 17/30\n",
      " 75/100 [=====================>........] - ETA: 13s - loss: 0.5881 - acc: 0.7933"
     ]
    }
   ],
   "source": [
    "# Run model\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 100,\n",
    "    epochs = 30,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display acc & loss curves during training and validation\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "acc = model.evaluate_generator(validation_generator, steps=100, verbose=0)\n",
    "print('> %.3f' % (acc * 100.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
